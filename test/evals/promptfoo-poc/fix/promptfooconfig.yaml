# This configuration compares LLM output of 2 prompts x 2 GPT models across 3 test cases.
# Learn more: https://promptfoo.dev/docs/configuration/guide
description: "fix"

prompts:
  - file://fix.prompt.txt

providers:
  - file://fix.provider.yml
defaultTest:
  assert:
    - type: is-json
    - type: is-valid-openai-tools-call
    - type: javascript
      value: |
        var args = JSON.parse(output[0].function.arguments)
        return (
          args.problems && 
          args.changes.length > 0 &&
          args.changes.some(
            change => change.hasChange && 
                      change.new.includes("var contextRmCmd = &cobra.Command{")
          )
        )

tests: tests/*.test.yml
